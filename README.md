# Creating s Sample Dataset from Large a Dataset

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)

A step-by-step guide to creating smaller, manageable datasets from large datasets using **Flickr30k** as an example. Perfect for prototyping image-captioning models or testing pipelines without overwhelming computational resources.

---

## ğŸ“– Overview

This repository demonstrates how to programmatically extract a **subset of images and their captions** from a large dataset while preserving the original structure. The example uses the [Flickr30k dataset](https://www.kaggle.com/datasets/adityajn105/flickr30k), but the code can be adapted to other datasets (e.g., COCO, custom datasets) with minimal changes.

**Check out the accompanying [Kaggle Notebook](https://www.kaggle.com/code/sayemuzzaman/create-a-small-sample-dataset-from-a-large-dataset) for a hands-on implementation walkthrough!**

**Key Features**:
- ğŸ¯ **Random Sampling**: Select `N` random images from a large dataset.
- ğŸ“‚ **Structure Preservation**: Copy images and their corresponding captions to a new directory.
- ğŸ–¼ï¸ **Visualization**: Display sample images with captions for verification.
- ğŸ”„ **Reproducibility**: Fix random seeds for consistent sampling across runs.

---

## ğŸ™ Acknowledgements

- The [Flickr30k dataset](https://www.kaggle.com/datasets/adityajn105/flickr30k) for providing the example data.
- **Connect with me**:

  [![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@sayemuzzamansiam)
  [![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/sayemuzzamansiam/)
  [![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)](https://www.kaggle.com/sayemuzzaman)
